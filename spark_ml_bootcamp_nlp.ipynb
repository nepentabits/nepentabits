{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark-ml-bootcamp-nlp.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMISpTIST0LrNoHdrNr/LxQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nepentabits/nepentabits.github.io/blob/master/spark_ml_bootcamp_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShqMPs1IrG4v",
        "colab_type": "text"
      },
      "source": [
        "Setup Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OfvLZ2ErM8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://apache.uvigo.es/spark/spark-2.4.5/spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.5-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "!pip install py4j\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUIBFGqlrQoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init(\"spark-2.4.5-bin-hadoop2.7\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plBGj2KmrWOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark import SparkContext\n",
        "\n",
        "# SPARK_HOME\n",
        "# create the session\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .appName(\"Datahack Spark demo\")  \\\n",
        "    .config(\"spark.ui.port\", \"4050\") \\\n",
        "    .getOrCreate() \n",
        "sc= spark.sparkContext\n",
        "\n",
        "#we have initialized the latest version of spark\n",
        "spark.version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veHa9QiIrbXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a sample text consisting of three documents\n",
        "inputDF = spark.createDataFrame([(0, \"Esto es un manzana. La manzana es una fruta, no una verdura.\"), \n",
        "                                 (1, \"Me gustan las frutas. Las frutas son buenas.\"),\n",
        "                                 (2, \"La verdura es buena, pero para mi las verduras no son buenas. Son malas.\")],\n",
        "                                 [\"id\",\"document\"])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}